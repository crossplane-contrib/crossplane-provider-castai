/*
Copyright 2022 Upbound Inc.
*/

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type AntiAffinityInitParameters struct {

	// affinity should be considered when scaling the workload.
	// If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.
	// Defines if anti-affinity should be considered when scaling the workload.
	// If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.
	ConsiderAntiAffinity *bool `json:"considerAntiAffinity,omitempty" tf:"consider_anti_affinity,omitempty"`
}

type AntiAffinityObservation struct {

	// affinity should be considered when scaling the workload.
	// If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.
	// Defines if anti-affinity should be considered when scaling the workload.
	// If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.
	ConsiderAntiAffinity *bool `json:"considerAntiAffinity,omitempty" tf:"consider_anti_affinity,omitempty"`
}

type AntiAffinityParameters struct {

	// affinity should be considered when scaling the workload.
	// If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.
	// Defines if anti-affinity should be considered when scaling the workload.
	// If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.
	// +kubebuilder:validation:Optional
	ConsiderAntiAffinity *bool `json:"considerAntiAffinity,omitempty" tf:"consider_anti_affinity,omitempty"`
}

type ApplyThresholdStrategyInitParameters struct {

	// (String) If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Denominator *string `json:"denominator,omitempty" tf:"denominator,omitempty"`

	// (Number) The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// - if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
	// - if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
	// It must be defined for the CUSTOM_ADAPTIVE strategy.
	Exponent *float64 `json:"exponent,omitempty" tf:"exponent,omitempty"`

	// smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Numerator *float64 `json:"numerator,omitempty" tf:"numerator,omitempty"`

	// (Number) Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	Percentage *float64 `json:"percentage,omitempty" tf:"percentage,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines apply theshold strategy type.
	// - PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
	// - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type ApplyThresholdStrategyObservation struct {

	// (String) If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Denominator *string `json:"denominator,omitempty" tf:"denominator,omitempty"`

	// (Number) The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// - if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
	// - if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
	// It must be defined for the CUSTOM_ADAPTIVE strategy.
	Exponent *float64 `json:"exponent,omitempty" tf:"exponent,omitempty"`

	// smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Numerator *float64 `json:"numerator,omitempty" tf:"numerator,omitempty"`

	// (Number) Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	Percentage *float64 `json:"percentage,omitempty" tf:"percentage,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines apply theshold strategy type.
	// - PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
	// - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type ApplyThresholdStrategyParameters struct {

	// (String) If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// +kubebuilder:validation:Optional
	Denominator *string `json:"denominator,omitempty" tf:"denominator,omitempty"`

	// (Number) The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// - if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
	// - if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
	// It must be defined for the CUSTOM_ADAPTIVE strategy.
	// +kubebuilder:validation:Optional
	Exponent *float64 `json:"exponent,omitempty" tf:"exponent,omitempty"`

	// smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// +kubebuilder:validation:Optional
	Numerator *float64 `json:"numerator,omitempty" tf:"numerator,omitempty"`

	// (Number) Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	// +kubebuilder:validation:Optional
	Percentage *float64 `json:"percentage,omitempty" tf:"percentage,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines apply theshold strategy type.
	// - PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
	// - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type AssignmentRulesInitParameters struct {

	// (Block List, Min: 1) (see below for nested schema)
	Rules []RulesInitParameters `json:"rules,omitempty" tf:"rules,omitempty"`
}

type AssignmentRulesObservation struct {

	// (Block List, Min: 1) (see below for nested schema)
	Rules []RulesObservation `json:"rules,omitempty" tf:"rules,omitempty"`
}

type AssignmentRulesParameters struct {

	// (Block List, Min: 1) (see below for nested schema)
	// +kubebuilder:validation:Optional
	Rules []RulesParameters `json:"rules" tf:"rules,omitempty"`
}

type ConfidenceInitParameters struct {

	// changing this value can cause applying less precise recommendations. Do not change the default unless you want to optimize with fewer data points (e.g., short-lived workloads).
	// Defines the confidence threshold for applying recommendations. The smaller number indicates that we require fewer metrics data points to apply recommendations - changing this value can cause applying less precise recommendations. Do not change the default unless you want to optimize with fewer data points (e.g., short-lived workloads).
	Threshold *float64 `json:"threshold,omitempty" tf:"threshold,omitempty"`
}

type ConfidenceObservation struct {

	// changing this value can cause applying less precise recommendations. Do not change the default unless you want to optimize with fewer data points (e.g., short-lived workloads).
	// Defines the confidence threshold for applying recommendations. The smaller number indicates that we require fewer metrics data points to apply recommendations - changing this value can cause applying less precise recommendations. Do not change the default unless you want to optimize with fewer data points (e.g., short-lived workloads).
	Threshold *float64 `json:"threshold,omitempty" tf:"threshold,omitempty"`
}

type ConfidenceParameters struct {

	// changing this value can cause applying less precise recommendations. Do not change the default unless you want to optimize with fewer data points (e.g., short-lived workloads).
	// Defines the confidence threshold for applying recommendations. The smaller number indicates that we require fewer metrics data points to apply recommendations - changing this value can cause applying less precise recommendations. Do not change the default unless you want to optimize with fewer data points (e.g., short-lived workloads).
	// +kubebuilder:validation:Optional
	Threshold *float64 `json:"threshold,omitempty" tf:"threshold,omitempty"`
}

type DownscalingInitParameters struct {

	// (String) Recommendation apply type.
	// Defines the apply type to be used when downscaling.
	// - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType *string `json:"applyType,omitempty" tf:"apply_type,omitempty"`
}

type DownscalingObservation struct {

	// (String) Recommendation apply type.
	// Defines the apply type to be used when downscaling.
	// - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType *string `json:"applyType,omitempty" tf:"apply_type,omitempty"`
}

type DownscalingParameters struct {

	// (String) Recommendation apply type.
	// Defines the apply type to be used when downscaling.
	// - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	// +kubebuilder:validation:Optional
	ApplyType *string `json:"applyType,omitempty" tf:"apply_type,omitempty"`
}

type LabelsExpressionsInitParameters struct {

	// (String) The label key to match. Required for all operators except Regex and Contains. If not specified, it will search through all labels.
	// The label key to match. Required for all operators except `Regex` and `Contains`. If not specified, it will search through all labels.
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String) The operator to use for matching the label.
	// The operator to use for matching the label.
	Operator *string `json:"operator,omitempty" tf:"operator,omitempty"`

	// (List of String) A list of values to match against the label key. It is required for In, NotIn, Regex, and Contains operators.
	// A list of values to match against the label key. It is required for `In`, `NotIn`, `Regex`, and `Contains` operators.
	Values []*string `json:"values,omitempty" tf:"values,omitempty"`
}

type LabelsExpressionsObservation struct {

	// (String) The label key to match. Required for all operators except Regex and Contains. If not specified, it will search through all labels.
	// The label key to match. Required for all operators except `Regex` and `Contains`. If not specified, it will search through all labels.
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String) The operator to use for matching the label.
	// The operator to use for matching the label.
	Operator *string `json:"operator,omitempty" tf:"operator,omitempty"`

	// (List of String) A list of values to match against the label key. It is required for In, NotIn, Regex, and Contains operators.
	// A list of values to match against the label key. It is required for `In`, `NotIn`, `Regex`, and `Contains` operators.
	Values []*string `json:"values,omitempty" tf:"values,omitempty"`
}

type LabelsExpressionsParameters struct {

	// (String) The label key to match. Required for all operators except Regex and Contains. If not specified, it will search through all labels.
	// The label key to match. Required for all operators except `Regex` and `Contains`. If not specified, it will search through all labels.
	// +kubebuilder:validation:Optional
	Key *string `json:"key,omitempty" tf:"key,omitempty"`

	// (String) The operator to use for matching the label.
	// The operator to use for matching the label.
	// +kubebuilder:validation:Optional
	Operator *string `json:"operator" tf:"operator,omitempty"`

	// (List of String) A list of values to match against the label key. It is required for In, NotIn, Regex, and Contains operators.
	// A list of values to match against the label key. It is required for `In`, `NotIn`, `Regex`, and `Contains` operators.
	// +kubebuilder:validation:Optional
	Values []*string `json:"values,omitempty" tf:"values,omitempty"`
}

type LimitInitParameters struct {

	// (Number) Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	Multiplier *float64 `json:"multiplier,omitempty" tf:"multiplier,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines limit strategy type.
	// - NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	// - KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
	// - MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type LimitObservation struct {

	// (Number) Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	Multiplier *float64 `json:"multiplier,omitempty" tf:"multiplier,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines limit strategy type.
	// - NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	// - KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
	// - MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type LimitParameters struct {

	// (Number) Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	// +kubebuilder:validation:Optional
	Multiplier *float64 `json:"multiplier,omitempty" tf:"multiplier,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines limit strategy type.
	// - NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	// - KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
	// - MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type MemoryApplyThresholdStrategyInitParameters struct {

	// (String) If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Denominator *string `json:"denominator,omitempty" tf:"denominator,omitempty"`

	// (Number) The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// - if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
	// - if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
	// It must be defined for the CUSTOM_ADAPTIVE strategy.
	Exponent *float64 `json:"exponent,omitempty" tf:"exponent,omitempty"`

	// smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Numerator *float64 `json:"numerator,omitempty" tf:"numerator,omitempty"`

	// (Number) Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	Percentage *float64 `json:"percentage,omitempty" tf:"percentage,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines apply theshold strategy type.
	// - PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
	// - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type MemoryApplyThresholdStrategyObservation struct {

	// (String) If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Denominator *string `json:"denominator,omitempty" tf:"denominator,omitempty"`

	// (Number) The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// - if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
	// - if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
	// It must be defined for the CUSTOM_ADAPTIVE strategy.
	Exponent *float64 `json:"exponent,omitempty" tf:"exponent,omitempty"`

	// smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Numerator *float64 `json:"numerator,omitempty" tf:"numerator,omitempty"`

	// (Number) Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	Percentage *float64 `json:"percentage,omitempty" tf:"percentage,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines apply theshold strategy type.
	// - PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
	// - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type MemoryApplyThresholdStrategyParameters struct {

	// (String) If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// +kubebuilder:validation:Optional
	Denominator *string `json:"denominator,omitempty" tf:"denominator,omitempty"`

	// (Number) The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// - if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
	// - if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
	// It must be defined for the CUSTOM_ADAPTIVE strategy.
	// +kubebuilder:validation:Optional
	Exponent *float64 `json:"exponent,omitempty" tf:"exponent,omitempty"`

	// smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	// +kubebuilder:validation:Optional
	Numerator *float64 `json:"numerator,omitempty" tf:"numerator,omitempty"`

	// (Number) Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	// +kubebuilder:validation:Optional
	Percentage *float64 `json:"percentage,omitempty" tf:"percentage,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines apply theshold strategy type.
	// - PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
	// - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type MemoryEventInitParameters struct {

	// (String) Recommendation apply type.
	// Defines the apply type to be used when applying recommendation for memory related event.
	// - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType *string `json:"applyType,omitempty" tf:"apply_type,omitempty"`
}

type MemoryEventObservation struct {

	// (String) Recommendation apply type.
	// Defines the apply type to be used when applying recommendation for memory related event.
	// - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType *string `json:"applyType,omitempty" tf:"apply_type,omitempty"`
}

type MemoryEventParameters struct {

	// (String) Recommendation apply type.
	// Defines the apply type to be used when applying recommendation for memory related event.
	// - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	// +kubebuilder:validation:Optional
	ApplyType *string `json:"applyType,omitempty" tf:"apply_type,omitempty"`
}

type MemoryInitParameters struct {

	// (Number, Deprecated) The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	ApplyThreshold *float64 `json:"applyThreshold,omitempty" tf:"apply_threshold,omitempty"`

	// (Block List, Max: 1) Resource apply threshold strategy settings. The default strategy is PERCENTAGE with percentage value set to 0.1. (see below for nested schema)
	// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
	ApplyThresholdStrategy []MemoryApplyThresholdStrategyInitParameters `json:"applyThresholdStrategy,omitempty" tf:"apply_threshold_strategy,omitempty"`

	// i.e. for QUANTILE this should be a [0, 1] float. MAX doesn't accept any args
	// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
	Args []*string `json:"args,omitempty" tf:"args,omitempty"`

	// (String) The function used to calculate the resource recommendation. Supported values: QUANTILE, MAX
	// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// (Block List, Max: 1) Resource limit settings (see below for nested schema)
	// Resource limit settings
	Limit []MemoryLimitInitParameters `json:"limit,omitempty" tf:"limit,omitempty"`

	// (Number) The look back period in seconds for the recommendation.
	// The look back period in seconds for the recommendation.
	LookBackPeriodSeconds *float64 `json:"lookBackPeriodSeconds,omitempty" tf:"look_back_period_seconds,omitempty"`

	// (String) Defines possible options for workload management.
	// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
	ManagementOption *string `json:"managementOption,omitempty" tf:"management_option,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Max *float64 `json:"max,omitempty" tf:"max,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Min *float64 `json:"min,omitempty" tf:"min,omitempty"`

	// (Number) Overhead for the recommendation, e.g. 0.1 will result in 10% higher recommendation
	// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
	Overhead *float64 `json:"overhead,omitempty" tf:"overhead,omitempty"`
}

type MemoryLimitInitParameters struct {

	// (Number) Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	Multiplier *float64 `json:"multiplier,omitempty" tf:"multiplier,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines limit strategy type.
	// - NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	// - KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
	// - MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type MemoryLimitObservation struct {

	// (Number) Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	Multiplier *float64 `json:"multiplier,omitempty" tf:"multiplier,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines limit strategy type.
	// - NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	// - KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
	// - MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type MemoryLimitParameters struct {

	// (Number) Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	// +kubebuilder:validation:Optional
	Multiplier *float64 `json:"multiplier,omitempty" tf:"multiplier,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines limit strategy type.
	// - NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	// - KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
	// - MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
	// +kubebuilder:validation:Optional
	Type *string `json:"type" tf:"type,omitempty"`
}

type MemoryObservation struct {

	// (Number, Deprecated) The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	ApplyThreshold *float64 `json:"applyThreshold,omitempty" tf:"apply_threshold,omitempty"`

	// (Block List, Max: 1) Resource apply threshold strategy settings. The default strategy is PERCENTAGE with percentage value set to 0.1. (see below for nested schema)
	// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
	ApplyThresholdStrategy []MemoryApplyThresholdStrategyObservation `json:"applyThresholdStrategy,omitempty" tf:"apply_threshold_strategy,omitempty"`

	// i.e. for QUANTILE this should be a [0, 1] float. MAX doesn't accept any args
	// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
	Args []*string `json:"args,omitempty" tf:"args,omitempty"`

	// (String) The function used to calculate the resource recommendation. Supported values: QUANTILE, MAX
	// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// (Block List, Max: 1) Resource limit settings (see below for nested schema)
	// Resource limit settings
	Limit []MemoryLimitObservation `json:"limit,omitempty" tf:"limit,omitempty"`

	// (Number) The look back period in seconds for the recommendation.
	// The look back period in seconds for the recommendation.
	LookBackPeriodSeconds *float64 `json:"lookBackPeriodSeconds,omitempty" tf:"look_back_period_seconds,omitempty"`

	// (String) Defines possible options for workload management.
	// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
	ManagementOption *string `json:"managementOption,omitempty" tf:"management_option,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Max *float64 `json:"max,omitempty" tf:"max,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Min *float64 `json:"min,omitempty" tf:"min,omitempty"`

	// (Number) Overhead for the recommendation, e.g. 0.1 will result in 10% higher recommendation
	// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
	Overhead *float64 `json:"overhead,omitempty" tf:"overhead,omitempty"`
}

type MemoryParameters struct {

	// (Number, Deprecated) The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// +kubebuilder:validation:Optional
	ApplyThreshold *float64 `json:"applyThreshold,omitempty" tf:"apply_threshold,omitempty"`

	// (Block List, Max: 1) Resource apply threshold strategy settings. The default strategy is PERCENTAGE with percentage value set to 0.1. (see below for nested schema)
	// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
	// +kubebuilder:validation:Optional
	ApplyThresholdStrategy []MemoryApplyThresholdStrategyParameters `json:"applyThresholdStrategy,omitempty" tf:"apply_threshold_strategy,omitempty"`

	// i.e. for QUANTILE this should be a [0, 1] float. MAX doesn't accept any args
	// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
	// +kubebuilder:validation:Optional
	Args []*string `json:"args,omitempty" tf:"args,omitempty"`

	// (String) The function used to calculate the resource recommendation. Supported values: QUANTILE, MAX
	// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
	// +kubebuilder:validation:Optional
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// (Block List, Max: 1) Resource limit settings (see below for nested schema)
	// Resource limit settings
	// +kubebuilder:validation:Optional
	Limit []MemoryLimitParameters `json:"limit,omitempty" tf:"limit,omitempty"`

	// (Number) The look back period in seconds for the recommendation.
	// The look back period in seconds for the recommendation.
	// +kubebuilder:validation:Optional
	LookBackPeriodSeconds *float64 `json:"lookBackPeriodSeconds,omitempty" tf:"look_back_period_seconds,omitempty"`

	// (String) Defines possible options for workload management.
	// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
	// +kubebuilder:validation:Optional
	ManagementOption *string `json:"managementOption,omitempty" tf:"management_option,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	// +kubebuilder:validation:Optional
	Max *float64 `json:"max,omitempty" tf:"max,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	// +kubebuilder:validation:Optional
	Min *float64 `json:"min,omitempty" tf:"min,omitempty"`

	// (Number) Overhead for the recommendation, e.g. 0.1 will result in 10% higher recommendation
	// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
	// +kubebuilder:validation:Optional
	Overhead *float64 `json:"overhead,omitempty" tf:"overhead,omitempty"`
}

type NamespaceInitParameters struct {

	// (List of String) Defines matching by namespace names.
	// Defines matching by namespace names.
	Names []*string `json:"names,omitempty" tf:"names,omitempty"`
}

type NamespaceObservation struct {

	// (List of String) Defines matching by namespace names.
	// Defines matching by namespace names.
	Names []*string `json:"names,omitempty" tf:"names,omitempty"`
}

type NamespaceParameters struct {

	// (List of String) Defines matching by namespace names.
	// Defines matching by namespace names.
	// +kubebuilder:validation:Optional
	Names []*string `json:"names,omitempty" tf:"names,omitempty"`
}

type PredictiveScalingCPUInitParameters struct {

	// (Boolean) Defines if predictive scaling is enabled for resource.
	// Defines if predictive scaling is enabled for resource.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type PredictiveScalingCPUObservation struct {

	// (Boolean) Defines if predictive scaling is enabled for resource.
	// Defines if predictive scaling is enabled for resource.
	Enabled *bool `json:"enabled,omitempty" tf:"enabled,omitempty"`
}

type PredictiveScalingCPUParameters struct {

	// (Boolean) Defines if predictive scaling is enabled for resource.
	// Defines if predictive scaling is enabled for resource.
	// +kubebuilder:validation:Optional
	Enabled *bool `json:"enabled" tf:"enabled,omitempty"`
}

type PredictiveScalingInitParameters struct {

	// (Block List, Min: 1, Max: 1) (see below for nested schema)
	// Defines predictive scaling resource configuration.
	CPU []PredictiveScalingCPUInitParameters `json:"cpu,omitempty" tf:"cpu,omitempty"`
}

type PredictiveScalingObservation struct {

	// (Block List, Min: 1, Max: 1) (see below for nested schema)
	// Defines predictive scaling resource configuration.
	CPU []PredictiveScalingCPUObservation `json:"cpu,omitempty" tf:"cpu,omitempty"`
}

type PredictiveScalingParameters struct {

	// (Block List, Min: 1, Max: 1) (see below for nested schema)
	// Defines predictive scaling resource configuration.
	// +kubebuilder:validation:Optional
	CPU []PredictiveScalingCPUParameters `json:"cpu,omitempty" tf:"cpu,omitempty"`
}

type RolloutBehaviorInitParameters struct {

	// (Boolean) Defines if pods should be restarted one by one to avoid service disruption.
	// Defines if pods should be restarted one by one to avoid service disruption.
	PreferOneByOne *bool `json:"preferOneByOne,omitempty" tf:"prefer_one_by_one,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines the rollout type to be used when applying recommendations.
	// - NO_DISRUPTION - pods are restarted without causing service disruption.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type RolloutBehaviorObservation struct {

	// (Boolean) Defines if pods should be restarted one by one to avoid service disruption.
	// Defines if pods should be restarted one by one to avoid service disruption.
	PreferOneByOne *bool `json:"preferOneByOne,omitempty" tf:"prefer_one_by_one,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines the rollout type to be used when applying recommendations.
	// - NO_DISRUPTION - pods are restarted without causing service disruption.
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type RolloutBehaviorParameters struct {

	// (Boolean) Defines if pods should be restarted one by one to avoid service disruption.
	// Defines if pods should be restarted one by one to avoid service disruption.
	// +kubebuilder:validation:Optional
	PreferOneByOne *bool `json:"preferOneByOne,omitempty" tf:"prefer_one_by_one,omitempty"`

	// (String) Defines apply theshold strategy type.
	// Defines the rollout type to be used when applying recommendations.
	// - NO_DISRUPTION - pods are restarted without causing service disruption.
	// +kubebuilder:validation:Optional
	Type *string `json:"type,omitempty" tf:"type,omitempty"`
}

type RulesInitParameters struct {

	// (Block List, Max: 1) Allows assigning a scaling policy based on the workload's namespace. (see below for nested schema)
	// Allows assigning a scaling policy based on the workload's namespace.
	Namespace []NamespaceInitParameters `json:"namespace,omitempty" tf:"namespace,omitempty"`

	// (Block List, Max: 1) Allows assigning a scaling policy based on the workload's metadata. (see below for nested schema)
	// Allows assigning a scaling policy based on the workload's metadata.
	Workload []WorkloadInitParameters `json:"workload,omitempty" tf:"workload,omitempty"`
}

type RulesObservation struct {

	// (Block List, Max: 1) Allows assigning a scaling policy based on the workload's namespace. (see below for nested schema)
	// Allows assigning a scaling policy based on the workload's namespace.
	Namespace []NamespaceObservation `json:"namespace,omitempty" tf:"namespace,omitempty"`

	// (Block List, Max: 1) Allows assigning a scaling policy based on the workload's metadata. (see below for nested schema)
	// Allows assigning a scaling policy based on the workload's metadata.
	Workload []WorkloadObservation `json:"workload,omitempty" tf:"workload,omitempty"`
}

type RulesParameters struct {

	// (Block List, Max: 1) Allows assigning a scaling policy based on the workload's namespace. (see below for nested schema)
	// Allows assigning a scaling policy based on the workload's namespace.
	// +kubebuilder:validation:Optional
	Namespace []NamespaceParameters `json:"namespace,omitempty" tf:"namespace,omitempty"`

	// (Block List, Max: 1) Allows assigning a scaling policy based on the workload's metadata. (see below for nested schema)
	// Allows assigning a scaling policy based on the workload's metadata.
	// +kubebuilder:validation:Optional
	Workload []WorkloadParameters `json:"workload,omitempty" tf:"workload,omitempty"`
}

type ScalingPolicyCPUInitParameters struct {

	// (Number, Deprecated) The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	ApplyThreshold *float64 `json:"applyThreshold,omitempty" tf:"apply_threshold,omitempty"`

	// (Block List, Max: 1) Resource apply threshold strategy settings. The default strategy is PERCENTAGE with percentage value set to 0.1. (see below for nested schema)
	// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
	ApplyThresholdStrategy []ApplyThresholdStrategyInitParameters `json:"applyThresholdStrategy,omitempty" tf:"apply_threshold_strategy,omitempty"`

	// i.e. for QUANTILE this should be a [0, 1] float. MAX doesn't accept any args
	// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
	Args []*string `json:"args,omitempty" tf:"args,omitempty"`

	// (String) The function used to calculate the resource recommendation. Supported values: QUANTILE, MAX
	// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// (Block List, Max: 1) Resource limit settings (see below for nested schema)
	// Resource limit settings
	Limit []LimitInitParameters `json:"limit,omitempty" tf:"limit,omitempty"`

	// (Number) The look back period in seconds for the recommendation.
	// The look back period in seconds for the recommendation.
	LookBackPeriodSeconds *float64 `json:"lookBackPeriodSeconds,omitempty" tf:"look_back_period_seconds,omitempty"`

	// (String) Defines possible options for workload management.
	// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
	ManagementOption *string `json:"managementOption,omitempty" tf:"management_option,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Max *float64 `json:"max,omitempty" tf:"max,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Min *float64 `json:"min,omitempty" tf:"min,omitempty"`

	// (Number) Overhead for the recommendation, e.g. 0.1 will result in 10% higher recommendation
	// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
	Overhead *float64 `json:"overhead,omitempty" tf:"overhead,omitempty"`
}

type ScalingPolicyCPUObservation struct {

	// (Number, Deprecated) The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	ApplyThreshold *float64 `json:"applyThreshold,omitempty" tf:"apply_threshold,omitempty"`

	// (Block List, Max: 1) Resource apply threshold strategy settings. The default strategy is PERCENTAGE with percentage value set to 0.1. (see below for nested schema)
	// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
	ApplyThresholdStrategy []ApplyThresholdStrategyObservation `json:"applyThresholdStrategy,omitempty" tf:"apply_threshold_strategy,omitempty"`

	// i.e. for QUANTILE this should be a [0, 1] float. MAX doesn't accept any args
	// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
	Args []*string `json:"args,omitempty" tf:"args,omitempty"`

	// (String) The function used to calculate the resource recommendation. Supported values: QUANTILE, MAX
	// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// (Block List, Max: 1) Resource limit settings (see below for nested schema)
	// Resource limit settings
	Limit []LimitObservation `json:"limit,omitempty" tf:"limit,omitempty"`

	// (Number) The look back period in seconds for the recommendation.
	// The look back period in seconds for the recommendation.
	LookBackPeriodSeconds *float64 `json:"lookBackPeriodSeconds,omitempty" tf:"look_back_period_seconds,omitempty"`

	// (String) Defines possible options for workload management.
	// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
	ManagementOption *string `json:"managementOption,omitempty" tf:"management_option,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Max *float64 `json:"max,omitempty" tf:"max,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Min *float64 `json:"min,omitempty" tf:"min,omitempty"`

	// (Number) Overhead for the recommendation, e.g. 0.1 will result in 10% higher recommendation
	// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
	Overhead *float64 `json:"overhead,omitempty" tf:"overhead,omitempty"`
}

type ScalingPolicyCPUParameters struct {

	// (Number, Deprecated) The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	// +kubebuilder:validation:Optional
	ApplyThreshold *float64 `json:"applyThreshold,omitempty" tf:"apply_threshold,omitempty"`

	// (Block List, Max: 1) Resource apply threshold strategy settings. The default strategy is PERCENTAGE with percentage value set to 0.1. (see below for nested schema)
	// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
	// +kubebuilder:validation:Optional
	ApplyThresholdStrategy []ApplyThresholdStrategyParameters `json:"applyThresholdStrategy,omitempty" tf:"apply_threshold_strategy,omitempty"`

	// i.e. for QUANTILE this should be a [0, 1] float. MAX doesn't accept any args
	// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
	// +kubebuilder:validation:Optional
	Args []*string `json:"args,omitempty" tf:"args,omitempty"`

	// (String) The function used to calculate the resource recommendation. Supported values: QUANTILE, MAX
	// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
	// +kubebuilder:validation:Optional
	Function *string `json:"function,omitempty" tf:"function,omitempty"`

	// (Block List, Max: 1) Resource limit settings (see below for nested schema)
	// Resource limit settings
	// +kubebuilder:validation:Optional
	Limit []LimitParameters `json:"limit,omitempty" tf:"limit,omitempty"`

	// (Number) The look back period in seconds for the recommendation.
	// The look back period in seconds for the recommendation.
	// +kubebuilder:validation:Optional
	LookBackPeriodSeconds *float64 `json:"lookBackPeriodSeconds,omitempty" tf:"look_back_period_seconds,omitempty"`

	// (String) Defines possible options for workload management.
	// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
	// +kubebuilder:validation:Optional
	ManagementOption *string `json:"managementOption,omitempty" tf:"management_option,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	// +kubebuilder:validation:Optional
	Max *float64 `json:"max,omitempty" tf:"max,omitempty"`

	// this is in MiB, for CPU - this is in cores.
	// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	// +kubebuilder:validation:Optional
	Min *float64 `json:"min,omitempty" tf:"min,omitempty"`

	// (Number) Overhead for the recommendation, e.g. 0.1 will result in 10% higher recommendation
	// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
	// +kubebuilder:validation:Optional
	Overhead *float64 `json:"overhead,omitempty" tf:"overhead,omitempty"`
}

type ScalingPolicyInitParameters struct {

	// (Block List, Max: 1) (see below for nested schema)
	AntiAffinity []AntiAffinityInitParameters `json:"antiAffinity,omitempty" tf:"anti_affinity,omitempty"`

	// (String) Recommendation apply type.
	// Recommendation apply type.
	// - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType *string `json:"applyType,omitempty" tf:"apply_type,omitempty"`

	// (Block List) Allows defining conditions for automatically assigning workloads to this scaling policy. (see below for nested schema)
	// Allows defining conditions for automatically assigning workloads to this scaling policy.
	AssignmentRules []AssignmentRulesInitParameters `json:"assignmentRules,omitempty" tf:"assignment_rules,omitempty"`

	// (Block List, Min: 1, Max: 1) (see below for nested schema)
	CPU []ScalingPolicyCPUInitParameters `json:"cpu,omitempty" tf:"cpu,omitempty"`

	// (String) CAST AI cluster id
	// CAST AI cluster id
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// (Block List, Max: 1) Defines the confidence settings for applying recommendations. (see below for nested schema)
	// Defines the confidence settings for applying recommendations.
	Confidence []ConfidenceInitParameters `json:"confidence,omitempty" tf:"confidence,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	Downscaling []DownscalingInitParameters `json:"downscaling,omitempty" tf:"downscaling,omitempty"`

	// (String) Defines possible options for workload management.
	// Defines possible options for workload management.
	// - READ_ONLY - workload watched (metrics collected), but no actions performed by CAST AI.
	// - MANAGED - workload watched (metrics collected), CAST AI may perform actions on the workload.
	ManagementOption *string `json:"managementOption,omitempty" tf:"management_option,omitempty"`

	// (Block List, Min: 1, Max: 1) (see below for nested schema)
	Memory []MemoryInitParameters `json:"memory,omitempty" tf:"memory,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	MemoryEvent []MemoryEventInitParameters `json:"memoryEvent,omitempty" tf:"memory_event,omitempty"`

	// (String) Scaling policy name
	// Scaling policy name
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	PredictiveScaling []PredictiveScalingInitParameters `json:"predictiveScaling,omitempty" tf:"predictive_scaling,omitempty"`

	// (Block List, Max: 1) Defines the rollout behavior used when applying recommendations. Prerequisites:
	// Defines the rollout behavior used when applying recommendations. Prerequisites:
	// - Applicable to Deployment resources that support running as multi-replica.
	// - Deployment is running with single replica (replica count = 1).
	// - Deployment's rollout strategy allows for downtime.
	// - Recommendation apply type is "immediate".
	// - Cluster has workload-autoscaler component version v0.35.3 or higher.
	RolloutBehavior []RolloutBehaviorInitParameters `json:"rolloutBehavior,omitempty" tf:"rollout_behavior,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	Startup []StartupInitParameters `json:"startup,omitempty" tf:"startup,omitempty"`
}

type ScalingPolicyObservation struct {

	// (Block List, Max: 1) (see below for nested schema)
	AntiAffinity []AntiAffinityObservation `json:"antiAffinity,omitempty" tf:"anti_affinity,omitempty"`

	// (String) Recommendation apply type.
	// Recommendation apply type.
	// - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType *string `json:"applyType,omitempty" tf:"apply_type,omitempty"`

	// (Block List) Allows defining conditions for automatically assigning workloads to this scaling policy. (see below for nested schema)
	// Allows defining conditions for automatically assigning workloads to this scaling policy.
	AssignmentRules []AssignmentRulesObservation `json:"assignmentRules,omitempty" tf:"assignment_rules,omitempty"`

	// (Block List, Min: 1, Max: 1) (see below for nested schema)
	CPU []ScalingPolicyCPUObservation `json:"cpu,omitempty" tf:"cpu,omitempty"`

	// (String) CAST AI cluster id
	// CAST AI cluster id
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// (Block List, Max: 1) Defines the confidence settings for applying recommendations. (see below for nested schema)
	// Defines the confidence settings for applying recommendations.
	Confidence []ConfidenceObservation `json:"confidence,omitempty" tf:"confidence,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	Downscaling []DownscalingObservation `json:"downscaling,omitempty" tf:"downscaling,omitempty"`

	// (String) The ID of this resource.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// (String) Defines possible options for workload management.
	// Defines possible options for workload management.
	// - READ_ONLY - workload watched (metrics collected), but no actions performed by CAST AI.
	// - MANAGED - workload watched (metrics collected), CAST AI may perform actions on the workload.
	ManagementOption *string `json:"managementOption,omitempty" tf:"management_option,omitempty"`

	// (Block List, Min: 1, Max: 1) (see below for nested schema)
	Memory []MemoryObservation `json:"memory,omitempty" tf:"memory,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	MemoryEvent []MemoryEventObservation `json:"memoryEvent,omitempty" tf:"memory_event,omitempty"`

	// (String) Scaling policy name
	// Scaling policy name
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	PredictiveScaling []PredictiveScalingObservation `json:"predictiveScaling,omitempty" tf:"predictive_scaling,omitempty"`

	// (Block List, Max: 1) Defines the rollout behavior used when applying recommendations. Prerequisites:
	// Defines the rollout behavior used when applying recommendations. Prerequisites:
	// - Applicable to Deployment resources that support running as multi-replica.
	// - Deployment is running with single replica (replica count = 1).
	// - Deployment's rollout strategy allows for downtime.
	// - Recommendation apply type is "immediate".
	// - Cluster has workload-autoscaler component version v0.35.3 or higher.
	RolloutBehavior []RolloutBehaviorObservation `json:"rolloutBehavior,omitempty" tf:"rollout_behavior,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	Startup []StartupObservation `json:"startup,omitempty" tf:"startup,omitempty"`
}

type ScalingPolicyParameters struct {

	// (Block List, Max: 1) (see below for nested schema)
	// +kubebuilder:validation:Optional
	AntiAffinity []AntiAffinityParameters `json:"antiAffinity,omitempty" tf:"anti_affinity,omitempty"`

	// (String) Recommendation apply type.
	// Recommendation apply type.
	// - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	// +kubebuilder:validation:Optional
	ApplyType *string `json:"applyType,omitempty" tf:"apply_type,omitempty"`

	// (Block List) Allows defining conditions for automatically assigning workloads to this scaling policy. (see below for nested schema)
	// Allows defining conditions for automatically assigning workloads to this scaling policy.
	// +kubebuilder:validation:Optional
	AssignmentRules []AssignmentRulesParameters `json:"assignmentRules,omitempty" tf:"assignment_rules,omitempty"`

	// (Block List, Min: 1, Max: 1) (see below for nested schema)
	// +kubebuilder:validation:Optional
	CPU []ScalingPolicyCPUParameters `json:"cpu,omitempty" tf:"cpu,omitempty"`

	// (String) CAST AI cluster id
	// CAST AI cluster id
	// +kubebuilder:validation:Optional
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// (Block List, Max: 1) Defines the confidence settings for applying recommendations. (see below for nested schema)
	// Defines the confidence settings for applying recommendations.
	// +kubebuilder:validation:Optional
	Confidence []ConfidenceParameters `json:"confidence,omitempty" tf:"confidence,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	// +kubebuilder:validation:Optional
	Downscaling []DownscalingParameters `json:"downscaling,omitempty" tf:"downscaling,omitempty"`

	// (String) Defines possible options for workload management.
	// Defines possible options for workload management.
	// - READ_ONLY - workload watched (metrics collected), but no actions performed by CAST AI.
	// - MANAGED - workload watched (metrics collected), CAST AI may perform actions on the workload.
	// +kubebuilder:validation:Optional
	ManagementOption *string `json:"managementOption,omitempty" tf:"management_option,omitempty"`

	// (Block List, Min: 1, Max: 1) (see below for nested schema)
	// +kubebuilder:validation:Optional
	Memory []MemoryParameters `json:"memory,omitempty" tf:"memory,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	// +kubebuilder:validation:Optional
	MemoryEvent []MemoryEventParameters `json:"memoryEvent,omitempty" tf:"memory_event,omitempty"`

	// (String) Scaling policy name
	// Scaling policy name
	// +kubebuilder:validation:Optional
	Name *string `json:"name,omitempty" tf:"name,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	// +kubebuilder:validation:Optional
	PredictiveScaling []PredictiveScalingParameters `json:"predictiveScaling,omitempty" tf:"predictive_scaling,omitempty"`

	// (Block List, Max: 1) Defines the rollout behavior used when applying recommendations. Prerequisites:
	// Defines the rollout behavior used when applying recommendations. Prerequisites:
	// - Applicable to Deployment resources that support running as multi-replica.
	// - Deployment is running with single replica (replica count = 1).
	// - Deployment's rollout strategy allows for downtime.
	// - Recommendation apply type is "immediate".
	// - Cluster has workload-autoscaler component version v0.35.3 or higher.
	// +kubebuilder:validation:Optional
	RolloutBehavior []RolloutBehaviorParameters `json:"rolloutBehavior,omitempty" tf:"rollout_behavior,omitempty"`

	// (Block List, Max: 1) (see below for nested schema)
	// +kubebuilder:validation:Optional
	Startup []StartupParameters `json:"startup,omitempty" tf:"startup,omitempty"`
}

type StartupInitParameters struct {

	// (Number) Defines the duration (in seconds) during which elevated resource usage is expected at startup.
	// When set, recommendations will be adjusted to disregard resource spikes within this period.
	// If not specified, the workload will receive standard recommendations without startup considerations.
	// Defines the duration (in seconds) during which elevated resource usage is expected at startup.
	// When set, recommendations will be adjusted to disregard resource spikes within this period.
	// If not specified, the workload will receive standard recommendations without startup considerations.
	PeriodSeconds *float64 `json:"periodSeconds,omitempty" tf:"period_seconds,omitempty"`
}

type StartupObservation struct {

	// (Number) Defines the duration (in seconds) during which elevated resource usage is expected at startup.
	// When set, recommendations will be adjusted to disregard resource spikes within this period.
	// If not specified, the workload will receive standard recommendations without startup considerations.
	// Defines the duration (in seconds) during which elevated resource usage is expected at startup.
	// When set, recommendations will be adjusted to disregard resource spikes within this period.
	// If not specified, the workload will receive standard recommendations without startup considerations.
	PeriodSeconds *float64 `json:"periodSeconds,omitempty" tf:"period_seconds,omitempty"`
}

type StartupParameters struct {

	// (Number) Defines the duration (in seconds) during which elevated resource usage is expected at startup.
	// When set, recommendations will be adjusted to disregard resource spikes within this period.
	// If not specified, the workload will receive standard recommendations without startup considerations.
	// Defines the duration (in seconds) during which elevated resource usage is expected at startup.
	// When set, recommendations will be adjusted to disregard resource spikes within this period.
	// If not specified, the workload will receive standard recommendations without startup considerations.
	// +kubebuilder:validation:Optional
	PeriodSeconds *float64 `json:"periodSeconds,omitempty" tf:"period_seconds,omitempty"`
}

type WorkloadInitParameters struct {

	// (List of String) Group, version, and kind for Kubernetes resources. Format: kind[.version][.group].
	// It can be either:
	// Group, version, and kind for Kubernetes resources. Format: kind[.version][.group].
	// It can be either:
	// - only kind, e.g. "Deployment"
	// - group and kind: e.g."Deployment.apps"
	// - group, version and kind: e.g."Deployment.v1.apps"
	Gvk []*string `json:"gvk,omitempty" tf:"gvk,omitempty"`

	// (Block List) Defines matching by label selector requirements. (see below for nested schema)
	// Defines matching by label selector requirements.
	LabelsExpressions []LabelsExpressionsInitParameters `json:"labelsExpressions,omitempty" tf:"labels_expressions,omitempty"`
}

type WorkloadObservation struct {

	// (List of String) Group, version, and kind for Kubernetes resources. Format: kind[.version][.group].
	// It can be either:
	// Group, version, and kind for Kubernetes resources. Format: kind[.version][.group].
	// It can be either:
	// - only kind, e.g. "Deployment"
	// - group and kind: e.g."Deployment.apps"
	// - group, version and kind: e.g."Deployment.v1.apps"
	Gvk []*string `json:"gvk,omitempty" tf:"gvk,omitempty"`

	// (Block List) Defines matching by label selector requirements. (see below for nested schema)
	// Defines matching by label selector requirements.
	LabelsExpressions []LabelsExpressionsObservation `json:"labelsExpressions,omitempty" tf:"labels_expressions,omitempty"`
}

type WorkloadParameters struct {

	// (List of String) Group, version, and kind for Kubernetes resources. Format: kind[.version][.group].
	// It can be either:
	// Group, version, and kind for Kubernetes resources. Format: kind[.version][.group].
	// It can be either:
	// - only kind, e.g. "Deployment"
	// - group and kind: e.g."Deployment.apps"
	// - group, version and kind: e.g."Deployment.v1.apps"
	// +kubebuilder:validation:Optional
	Gvk []*string `json:"gvk,omitempty" tf:"gvk,omitempty"`

	// (Block List) Defines matching by label selector requirements. (see below for nested schema)
	// Defines matching by label selector requirements.
	// +kubebuilder:validation:Optional
	LabelsExpressions []LabelsExpressionsParameters `json:"labelsExpressions,omitempty" tf:"labels_expressions,omitempty"`
}

// ScalingPolicySpec defines the desired state of ScalingPolicy
type ScalingPolicySpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     ScalingPolicyParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider ScalingPolicyInitParameters `json:"initProvider,omitempty"`
}

// ScalingPolicyStatus defines the observed state of ScalingPolicy.
type ScalingPolicyStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        ScalingPolicyObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// ScalingPolicy is the Schema for the ScalingPolicys API. Manage workload scaling policy. Scaling policy reference https://docs.cast.ai/docs/woop-scaling-policies
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,castai}
type ScalingPolicy struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.applyType) || (has(self.initProvider) && has(self.initProvider.applyType))",message="spec.forProvider.applyType is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.clusterId) || (has(self.initProvider) && has(self.initProvider.clusterId))",message="spec.forProvider.clusterId is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.cpu) || (has(self.initProvider) && has(self.initProvider.cpu))",message="spec.forProvider.cpu is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.managementOption) || (has(self.initProvider) && has(self.initProvider.managementOption))",message="spec.forProvider.managementOption is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.memory) || (has(self.initProvider) && has(self.initProvider.memory))",message="spec.forProvider.memory is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.name) || (has(self.initProvider) && has(self.initProvider.name))",message="spec.forProvider.name is a required parameter"
	Spec   ScalingPolicySpec   `json:"spec"`
	Status ScalingPolicyStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// ScalingPolicyList contains a list of ScalingPolicys
type ScalingPolicyList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []ScalingPolicy `json:"items"`
}

// Repository type metadata.
var (
	ScalingPolicy_Kind             = "ScalingPolicy"
	ScalingPolicy_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: ScalingPolicy_Kind}.String()
	ScalingPolicy_KindAPIVersion   = ScalingPolicy_Kind + "." + CRDGroupVersion.String()
	ScalingPolicy_GroupVersionKind = CRDGroupVersion.WithKind(ScalingPolicy_Kind)
)

func init() {
	SchemeBuilder.Register(&ScalingPolicy{}, &ScalingPolicyList{})
}
